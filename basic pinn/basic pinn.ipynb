{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schrodinger function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsInformedNN(nn.Module):\n",
    "    def __init__(self, X0, Y0, X_f, X_lb, X_ub, bounary, layers):\n",
    "        \"\"\"\n",
    "        X0: T=0, initial condition, randomly drawn from the domain\n",
    "        Y0: T=0, initial condition, given (u0, v0)\n",
    "        X_f: the collocation points with time, size (Nf, 2)\n",
    "        X_lb: the lower boundary, size (N_b, 2)\n",
    "        X_ub: the upper boundary, size (N_b, 2)\n",
    "        boundary: the lower and upper boundary, size (2, 2) : [(x_min, t_min), (x_max, t_max)]\n",
    "        layers: the number of neurons in each layer\n",
    "        \"\"\"\n",
    "        super(PhysicsInformedNN, self).__init__()\n",
    "\n",
    "        # Initial Data\n",
    "        self.x0 = torch.tensor(X0[:, 0:1], requires_grad=True)\n",
    "        self.t0 = torch.tensor(X0[:, 1:2], requires_grad=True)\n",
    "        \n",
    "        self.u0 = torch.tensor(Y0[:, 0:1])\n",
    "        self.v0 = torch.tensor(Y0[:, 1:2])\n",
    "        \n",
    "        # Boundary Data\n",
    "        self.x_lb = torch.tensor(X_lb[:, 0:1], requires_grad=True)\n",
    "        self.t_lb = torch.tensor(X_lb[:, 1:2], requires_grad=True)\n",
    "        self.x_ub = torch.tensor(X_ub[:, 0:1], requires_grad=True)\n",
    "        self.t_ub = torch.tensor(X_ub[:, 1:2], requires_grad=True)\n",
    "        \n",
    "        # Collocation Points\n",
    "        self.x_f = torch.tensor(X_f[:, 0:1], requires_grad=True)\n",
    "        self.t_f = torch.tensor(X_f[:, 1:2], requires_grad=True)\n",
    "        \n",
    "        # Bounds\n",
    "        self.lb = torch.tensor(bounary[:, 0:1])\n",
    "        self.ub = torch.tensor(bounary[:, 1:2])\n",
    "        \n",
    "        # Initialize NNs\n",
    "        self.layers = layers\n",
    "        self.model = nn.Sequential()\n",
    "        for l in range(0, len(layers) - 2):\n",
    "            self.model.add_module(\"linear\" + str(l), nn.Linear(layers[l], layers[l+1]))\n",
    "            self.model.add_module(\"tanh\" + str(l), nn.Tanh())\n",
    "        self.model.add_module(\"linear\" + str(len(layers) - 2), nn.Linear(layers[-2], layers[-1]))\n",
    "        self.model = self.model.double()\n",
    "\n",
    "    # calculate the function h(x, t) using neural nets\n",
    "    def net_uv(self, x, t):\n",
    "        X = torch.cat([x, t], dim=1)\n",
    "        H = (X - self.lb) / (self.ub - self.lb) * 2.0 - 1.0 # normalize to [-1, 1]\n",
    "        \n",
    "        uv = self.model(H)\n",
    "        u = uv[:, 0:1]\n",
    "        v = uv[:, 1:2]\n",
    "        u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "        v_x = torch.autograd.grad(v, x, grad_outputs=torch.ones_like(v), create_graph=True)[0]\n",
    "        return u, v, u_x, v_x\n",
    "\n",
    "    # compute the Schrodinger function on the collacation points\n",
    "    def net_f_uv(self, x, t):\n",
    "        u, v, u_x, v_x = self.net_uv(x, t)\n",
    "        u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "        u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u_x), create_graph=True)[0]\n",
    "        v_t = torch.autograd.grad(v, t, grad_outputs=torch.ones_like(v), create_graph=True)[0]\n",
    "        v_xx = torch.autograd.grad(v_x, x, grad_outputs=torch.ones_like(v_x), create_graph=True)[0]\n",
    "        f_u = u_t + 0.5*v_xx + (u**2 + v**2)*v\n",
    "        f_v = v_t - 0.5*u_xx - (u**2 + v**2)*u\n",
    "        return f_u, f_v\n",
    "\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        u, v, _, _ = self.net_uv(x, t)\n",
    "        f_u, f_v = self.net_f_uv(x, t)\n",
    "        return u, v, f_u, f_v\n",
    "\n",
    "    def loss_function(self):\n",
    "        loss = nn.MSELoss()\n",
    "        self.u0_pred, self.v0_pred, _, _ = self.net_uv(self.x0, self.t0)\n",
    "        \n",
    "        self.u_lb_pred, self.v_lb_pred, self.u_x_lb_pred, self.v_x_lb_pred = self.net_uv(self.x_lb, self.t_lb)\n",
    "        self.u_ub_pred, self.v_ub_pred, self.u_x_ub_pred, self.v_x_ub_pred = self.net_uv(self.x_ub, self.t_ub)\n",
    "        \n",
    "        self.f_u_pred, self.f_v_pred = self.net_f_uv(self.x_f, self.t_f)\n",
    "        \n",
    "        # initial condition + boundary condition + PDE constraint\n",
    "        MSE = loss(self.u0_pred, self.u0) + loss(self.v0_pred, self.v0) + \\\n",
    "            loss(self.u_lb_pred, self.u_ub_pred) + loss(self.v_lb_pred, self.v_ub_pred) + \\\n",
    "            loss(self.u_x_lb_pred, self.u_x_ub_pred) + loss(self.v_x_lb_pred, self.v_x_ub_pred) + \\\n",
    "            loss(self.f_u_pred, torch.zeros_like(self.f_u_pred)) + loss(self.f_v_pred, torch.zeros_like(self.f_v_pred))\n",
    "\n",
    "        return MSE\n",
    "    \n",
    "    def train(self, epochs = 1e+4, lr = 1e-3):\n",
    "        # Optimizer\n",
    "        optimizer = adam.Adam(self.model.parameters(), lr=lr)\n",
    "        \n",
    "        # Training\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            optimizer.zero_grad()\n",
    "            loss = self.loss_function()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if epoch % 100 == 0:\n",
    "                print('Epoch: %d, Loss: %.3e' % (epoch, loss.item()))\n",
    "\n",
    "    def predict(self, X_star):\n",
    "        u_star, v_star, f_u_star, f_v_star = self.forward(X_star[:, 0:1], X_star[:, 1:2])\n",
    "        return u_star.detach().numpy(), v_star.detach().numpy(), f_u_star.detach().numpy(), f_v_star.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_vhstack_dispatcher() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/finleyyu/Library/CloudStorage/Dropbox/Germany/2023ws/Generative neural networks/GenerativePINNs/basic pinn.ipynb 单元格 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/finleyyu/Library/CloudStorage/Dropbox/Germany/2023ws/Generative%20neural%20networks/GenerativePINNs/basic%20pinn.ipynb#X11sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m X0 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((x0, np\u001b[39m.\u001b[39mzeros_like(x0, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)), \u001b[39m1\u001b[39m) \u001b[39m# (x, 0)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/finleyyu/Library/CloudStorage/Dropbox/Germany/2023ws/Generative%20neural%20networks/GenerativePINNs/basic%20pinn.ipynb#X11sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# boundary points\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/finleyyu/Library/CloudStorage/Dropbox/Germany/2023ws/Generative%20neural%20networks/GenerativePINNs/basic%20pinn.ipynb#X11sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m boundary \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mhstack(lb, ub)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/finleyyu/Library/CloudStorage/Dropbox/Germany/2023ws/Generative%20neural%20networks/GenerativePINNs/basic%20pinn.ipynb#X11sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m X_lb \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((lb[\u001b[39m0\u001b[39m]\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39mones_like(tb, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32), tb), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/finleyyu/Library/CloudStorage/Dropbox/Germany/2023ws/Generative%20neural%20networks/GenerativePINNs/basic%20pinn.ipynb#X11sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m X_ub \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((ub[\u001b[39m0\u001b[39m]\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39mones_like(tb, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32), tb), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:179\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _vhstack_dispatcher() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "from pyDOE import lhs\n",
    "import time\n",
    "\n",
    "# Hyperparameters\n",
    "noise = 0.0        \n",
    "lb = np.array([-5.0, 0.0]) # lower bound for [x, t]\n",
    "ub = np.array([5.0, np.pi/2]) # upper bound for [x, t]\n",
    "N0 = 50 # number of data for initial samples\n",
    "N_b = 50 # number of data for boundary samples\n",
    "N_f = 20000 # number of data for collocation points\n",
    "\n",
    "# Define the physics-informed neural network\n",
    "layers = [2, 100, 100, 100, 100, 2]\n",
    "\n",
    "# Load data from simulated dataset\n",
    "data = scipy.io.loadmat('./Data/NLS.mat')\n",
    "\n",
    "\n",
    "t = data['tt'].flatten()[:,None]\n",
    "x = data['x'].flatten()[:,None]\n",
    "Exact = data['uu']\n",
    "Exact_h = np.sqrt(np.real(Exact)**2 + np.imag(Exact)**2)\n",
    "X, T = np.meshgrid(x,t)\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "h_star = Exact_h.T.flatten()[:,None]\n",
    "v_star = np.imag(Exact).T.flatten()[:,None]\n",
    "u_star = np.real(Exact).T.flatten()[:,None]\n",
    "\n",
    "# Initial and boundary data\n",
    "idx_x = np.random.choice(x.shape[0], N0, replace=False)\n",
    "x0 = x[idx_x,:]\n",
    "u0 = np.real(Exact[idx_x,0:1]) # or computed using h(0, x) = 2*sech(x)\n",
    "v0 = np.imag(Exact[idx_x,0:1])\n",
    "Y0 = np.hstack((u0, v0))\n",
    "tb = t[np.random.choice(t.shape[0], N_b, replace=False),:] # random time samples for boundary points\n",
    "\n",
    "# Collocation points\n",
    "X_f = lb + (ub-lb)*lhs(2, N_f)\n",
    "\n",
    "# initial points\n",
    "X0 = np.concatenate((x0, np.zeros_like(x0, dtype=np.float32)), 1) # (x, 0)\n",
    "\n",
    "# boundary points\n",
    "boundary = np.hstack(lb, ub)\n",
    "X_lb = np.concatenate((lb[0]*np.ones_like(tb, dtype=np.float32), tb), axis=1)\n",
    "X_ub = np.concatenate((ub[0]*np.ones_like(tb, dtype=np.float32), tb), axis=1)\n",
    "\n",
    "# Train the model\n",
    "model = PhysicsInformedNN(X0, Y0, X_f, X_lb, X_ub, boundary, layers)\n",
    "start_time = time.time()                \n",
    "model.train(2000)\n",
    "print('Training time: %.4f' % (time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors:  {'u': 0.9383029287087779, 'v': 1.217115660844033, 'h': 0.38263001697962795}\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "u_pred, v_pred, _, _ = model.predict(torch.tensor(X_star, requires_grad=True))\n",
    "h_pred = np.sqrt(u_pred**2 + v_pred**2)\n",
    "        \n",
    "# Errors\n",
    "errors = {'u': np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2),\n",
    "          'v': np.linalg.norm(v_star-v_pred,2)/np.linalg.norm(v_star,2),\n",
    "          'h': np.linalg.norm(h_star-h_pred,2)/np.linalg.norm(h_star,2)}\n",
    "print('Errors: ', errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
