{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schrodinger function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsInformedNN(nn.Module):\n",
    "    def __init__(self, X0, Y0, X_f, X_lb, X_ub, bounary, layers):\n",
    "        \"\"\"\n",
    "        X0: T=0, initial condition, randomly drawn from the domain\n",
    "        Y0: T=0, initial condition, given (u0, v0)\n",
    "        X_f: the collocation points with time, size (Nf, 2)\n",
    "        X_lb: the lower boundary, size (N_b, 2)\n",
    "        X_ub: the upper boundary, size (N_b, 2)\n",
    "        boundary: the lower and upper boundary, size (2, 2) : [(x_min, t_min), (x_max, t_max)]\n",
    "        layers: the number of neurons in each layer\n",
    "        \"\"\"\n",
    "        super(PhysicsInformedNN, self).__init__()\n",
    "\n",
    "        # Initial Data\n",
    "        self.x0 = torch.tensor(X0[:, 0:1], requires_grad=True)\n",
    "        self.t0 = torch.tensor(X0[:, 1:2], requires_grad=True)\n",
    "        \n",
    "        self.u0 = torch.tensor(Y0[:, 0:1])\n",
    "        self.v0 = torch.tensor(Y0[:, 1:2])\n",
    "        \n",
    "        # Boundary Data\n",
    "        self.x_lb = torch.tensor(X_lb[:, 0:1], requires_grad=True)\n",
    "        self.t_lb = torch.tensor(X_lb[:, 1:2], requires_grad=True)\n",
    "        self.x_ub = torch.tensor(X_ub[:, 0:1], requires_grad=True)\n",
    "        self.t_ub = torch.tensor(X_ub[:, 1:2], requires_grad=True)\n",
    "        \n",
    "        # Collocation Points\n",
    "        self.x_f = torch.tensor(X_f[:, 0:1], requires_grad=True)\n",
    "        self.t_f = torch.tensor(X_f[:, 1:2], requires_grad=True)\n",
    "        \n",
    "        # Bounds\n",
    "        self.lb = torch.tensor(bounary[0:1, :])\n",
    "        self.ub = torch.tensor(bounary[1:2, :])\n",
    "        \n",
    "        # Initialize NNs\n",
    "        self.layers = layers\n",
    "        self.model = nn.Sequential()\n",
    "        for l in range(0, len(layers) - 2):\n",
    "            self.model.add_module(\"linear\" + str(l), nn.Linear(layers[l], layers[l+1]))\n",
    "            self.model.add_module(\"tanh\" + str(l), nn.Tanh())\n",
    "        self.model.add_module(\"linear\" + str(len(layers) - 2), nn.Linear(layers[-2], layers[-1]))\n",
    "        self.model = self.model.double()\n",
    "\n",
    "    # calculate the function h(x, t) using neural nets\n",
    "    def net_uv(self, x, t):\n",
    "        X = torch.cat([x, t], dim=1)\n",
    "        H = (X - self.lb) / (self.ub - self.lb) * 2.0 - 1.0 # normalize to [-1, 1]\n",
    "        \n",
    "        uv = self.model(H)\n",
    "        u = uv[:, 0:1]\n",
    "        v = uv[:, 1:2]\n",
    "        u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "        v_x = torch.autograd.grad(v, x, grad_outputs=torch.ones_like(v), create_graph=True)[0]\n",
    "        return u, v, u_x, v_x\n",
    "\n",
    "    # compute the Schrodinger function on the collacation points\n",
    "    def net_f_uv(self, x, t):\n",
    "        u, v, u_x, v_x = self.net_uv(x, t)\n",
    "        u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "        u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u_x), create_graph=True)[0]\n",
    "        v_t = torch.autograd.grad(v, t, grad_outputs=torch.ones_like(v), create_graph=True)[0]\n",
    "        v_xx = torch.autograd.grad(v_x, x, grad_outputs=torch.ones_like(v_x), create_graph=True)[0]\n",
    "        f_u = u_t + 0.5*v_xx + (u**2 + v**2)*v\n",
    "        f_v = v_t - 0.5*u_xx - (u**2 + v**2)*u\n",
    "        return f_u, f_v\n",
    "\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        u, v, _, _ = self.net_uv(x, t)\n",
    "        f_u, f_v = self.net_f_uv(x, t)\n",
    "        return u, v, f_u, f_v\n",
    "\n",
    "    def loss_function(self):\n",
    "        loss = nn.MSELoss()\n",
    "        self.u0_pred, self.v0_pred, _, _ = self.net_uv(self.x0, self.t0)\n",
    "        \n",
    "        self.u_lb_pred, self.v_lb_pred, self.u_x_lb_pred, self.v_x_lb_pred = self.net_uv(self.x_lb, self.t_lb)\n",
    "        self.u_ub_pred, self.v_ub_pred, self.u_x_ub_pred, self.v_x_ub_pred = self.net_uv(self.x_ub, self.t_ub)\n",
    "        \n",
    "        self.f_u_pred, self.f_v_pred = self.net_f_uv(self.x_f, self.t_f)\n",
    "        \n",
    "        # initial condition + boundary condition + PDE constraint\n",
    "        MSE = loss(self.u0_pred, self.u0) + loss(self.v0_pred, self.v0) + \\\n",
    "            loss(self.u_lb_pred, self.u_ub_pred) + loss(self.v_lb_pred, self.v_ub_pred) + \\\n",
    "            loss(self.u_x_lb_pred, self.u_x_ub_pred) + loss(self.v_x_lb_pred, self.v_x_ub_pred) + \\\n",
    "            loss(self.f_u_pred, torch.zeros_like(self.f_u_pred)) + loss(self.f_v_pred, torch.zeros_like(self.f_v_pred))\n",
    "\n",
    "        return MSE\n",
    "    \n",
    "    def train(self, epochs = 1e+4, lr = 1e-3):\n",
    "        # Optimizer\n",
    "        optimizer = adam.Adam(self.model.parameters(), lr=lr)\n",
    "        \n",
    "        # Training\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            optimizer.zero_grad()\n",
    "            loss = self.loss_function()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if epoch % 100 == 0:\n",
    "                print('Epoch: %d, Loss: %.3e' % (epoch, loss.item()))\n",
    "\n",
    "    def predict(self, X_star):\n",
    "        u_star, v_star, f_u_star, f_v_star = self.forward(X_star[:, 0:1], X_star[:, 1:2])\n",
    "        return u_star.detach().numpy(), v_star.detach().numpy(), f_u_star.detach().numpy(), f_v_star.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:03<2:02:49,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 8.796e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 101/2000 [03:17<55:20,  1.75s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 1.218e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 201/2000 [06:23<50:26,  1.68s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200, Loss: 6.644e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 301/2000 [09:29<49:55,  1.76s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 300, Loss: 5.208e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 401/2000 [12:39<51:04,  1.92s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 400, Loss: 4.653e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 501/2000 [15:32<42:44,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 500, Loss: 4.402e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 601/2000 [18:29<46:26,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 600, Loss: 3.954e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 701/2000 [21:35<35:30,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 700, Loss: 3.695e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 801/2000 [24:37<35:57,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 800, Loss: 3.567e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 901/2000 [27:34<34:02,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 900, Loss: 3.331e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1001/2000 [30:27<26:38,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000, Loss: 3.302e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 1101/2000 [33:28<27:47,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1100, Loss: 3.294e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 1201/2000 [36:40<23:13,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1200, Loss: 2.971e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 1301/2000 [39:33<22:58,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1300, Loss: 2.873e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 1401/2000 [42:48<21:09,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1400, Loss: 4.429e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 1501/2000 [45:43<14:30,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1500, Loss: 4.354e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1601/2000 [49:29<11:51,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1600, Loss: 2.768e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 1701/2000 [52:53<10:28,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1700, Loss: 2.819e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 1801/2000 [56:34<07:12,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1800, Loss: 2.450e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 1901/2000 [59:43<02:46,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1900, Loss: 2.625e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [1:02:46<00:00,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 3766.8548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "from pyDOE import lhs\n",
    "import time\n",
    "\n",
    "# Hyperparameters\n",
    "noise = 0.0        \n",
    "lb = np.array([-5.0, 0.0]) # lower bound for [x, t]\n",
    "ub = np.array([5.0, np.pi/2]) # upper bound for [x, t]\n",
    "N0 = 50 # number of data for initial samples\n",
    "N_b = 50 # number of data for boundary samples\n",
    "N_f = 20000 # number of data for collocation points\n",
    "\n",
    "# Define the physics-informed neural network\n",
    "layers = [2, 100, 100, 100, 100, 2]\n",
    "\n",
    "# Load data from simulated dataset\n",
    "data = scipy.io.loadmat('./Data/schroedinger.mat')\n",
    "\n",
    "\n",
    "t = data['tt'].flatten()[:,None]\n",
    "x = data['x'].flatten()[:,None]\n",
    "Exact = data['uu']\n",
    "Exact_h = np.sqrt(np.real(Exact)**2 + np.imag(Exact)**2)\n",
    "X, T = np.meshgrid(x,t)\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "h_star = Exact_h.T.flatten()[:,None]\n",
    "v_star = np.imag(Exact).T.flatten()[:,None]\n",
    "u_star = np.real(Exact).T.flatten()[:,None]\n",
    "\n",
    "# Initial and boundary data\n",
    "idx_x = np.random.choice(x.shape[0], N0, replace=False)\n",
    "x0 = x[idx_x,:]\n",
    "u0 = np.real(Exact[idx_x,0:1]) # or computed using h(0, x) = 2*sech(x)\n",
    "v0 = np.imag(Exact[idx_x,0:1])\n",
    "Y0 = np.hstack((u0, v0))\n",
    "tb = t[np.random.choice(t.shape[0], N_b, replace=False),:] # random time samples for boundary points\n",
    "\n",
    "# Collocation points\n",
    "X_f = lb + (ub-lb)*lhs(2, N_f)\n",
    "\n",
    "# initial points\n",
    "X0 = np.concatenate((x0, np.zeros_like(x0, dtype=np.float32)), 1) # (x, 0)\n",
    "\n",
    "# boundary points\n",
    "boundary = np.vstack((lb, ub))\n",
    "X_lb = np.concatenate((lb[0]*np.ones_like(tb, dtype=np.float32), tb), axis=1)\n",
    "X_ub = np.concatenate((ub[0]*np.ones_like(tb, dtype=np.float32), tb), axis=1)\n",
    "\n",
    "# Train the model\n",
    "\n",
    "model = PhysicsInformedNN(X0, Y0, X_f, X_lb, X_ub, boundary, layers)\n",
    "start_time = time.time()                \n",
    "model.train(2000)\n",
    "print('Training time: %.4f' % (time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors:  {'u': 1.143717954329265, 'v': 1.2535130979684617, 'h': 0.35178049777675574}\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "u_pred, v_pred, _, _ = model.predict(torch.tensor(X_star, requires_grad=True))\n",
    "h_pred = np.sqrt(u_pred**2 + v_pred**2)\n",
    "        \n",
    "# Errors\n",
    "errors = {'u': np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2),\n",
    "          'v': np.linalg.norm(v_star-v_pred,2)/np.linalg.norm(v_star,2),\n",
    "          'h': np.linalg.norm(h_star-h_pred,2)/np.linalg.norm(h_star,2)}\n",
    "print('Errors: ', errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
