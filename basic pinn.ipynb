{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schrodinger function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsInformedNN(nn.Module):\n",
    "    def __init__(self, x0, u0, v0, tb, X_f, lb, ub, layers):\n",
    "        \"\"\"\n",
    "        x0: T=0, initial condition, randomly drawn from the domain\n",
    "        u0: the real part of the value\n",
    "        v0: the imaginary part of the value\n",
    "        tb: the time boundary\n",
    "        X_f: the collocation points with time, size (Nf, 2)\n",
    "        lb: the lower bound of the domain (x_min, t_min)\n",
    "        ub: the upper bound of the domain (x_max, t_max)\n",
    "        layers: the number of neurons in each layer\n",
    "        \"\"\"\n",
    "        super(PhysicsInformedNN, self).__init__()\n",
    "\n",
    "        # Data\n",
    "        self.X0 = torch.tensor(np.concatenate((x0, 0), 1)) # (x, 0)\n",
    "        self.X_f = torch.tensor(X_f)\n",
    "        self.X_lb = torch.tensor(np.concatenate((lb[0], tb), axis=1))\n",
    "        self.X_ub = torch.tensor(np.concatenate((ub[0], tb), axis=1))\n",
    "        \n",
    "        self.u0 = torch.tensor(u0)\n",
    "        self.v0 = torch.tensor(v0)\n",
    "\n",
    "        # Bounds\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "        \n",
    "        # Initialize NNs\n",
    "        self.layers = layers\n",
    "        self.model = nn.Sequential()\n",
    "        for l in range(0, len(layers) - 2):\n",
    "            self.model.add_module(\"linear\" + str(l), nn.Linear(layers[l], layers[l+1]))\n",
    "            self.model.add_module(\"tanh\" + str(l), nn.Tanh())\n",
    "        self.model.add_module(\"linear\" + str(len(layers) - 2), nn.Linear(layers[-2], layers[-1]))\n",
    "\n",
    "    # calculate the function h(x, t) using neural nets\n",
    "    def net_uv(self, x, t):\n",
    "        X = torch.cat([x, t], dim=1)\n",
    "        H = (X - self.lb) / (self.ub - self.lb) * 2.0 - 1.0 # normalize to [-1, 1]\n",
    "        uv = self.model(H)\n",
    "        u = uv[:, 0:1]\n",
    "        v = uv[:, 1:2]\n",
    "        u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "        v_x = torch.autograd.grad(v, x, grad_outputs=torch.ones_like(v), create_graph=True)[0]\n",
    "        return u, v, u_x, v_x\n",
    "\n",
    "    # compute the Schrodinger function on the collacation points\n",
    "    def net_f_uv(self, x, t):\n",
    "        u, v, u_x, v_x = self.net_uv(x, t)\n",
    "        u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "        u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u_x), create_graph=True)[0]\n",
    "        v_t = torch.autograd.grad(v, t, grad_outputs=torch.ones_like(v), create_graph=True)[0]\n",
    "        v_xx = torch.autograd.grad(v_x, x, grad_outputs=torch.ones_like(v_x), create_graph=True)[0]\n",
    "        f_u = u_t + 0.5*v_xx + (u**2 + v**2)*v\n",
    "        f_v = v_t - 0.5*u_xx - (u**2 + v**2)*u\n",
    "        return f_u, f_v\n",
    "\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        u, v, f_u, f_v = self.net_f_uv(x, t)\n",
    "        return u, v, f_u, f_v\n",
    "\n",
    "    def loss_function(self):\n",
    "        loss = nn.MSELoss()\n",
    "        self.u0_pred, self.v0_pred, _, _ = self.net_uv(self.x0, self.t0)\n",
    "        \n",
    "        self.u_lb_pred, self.v_lb_pred, self.u_x_lb_pred, self.v_x_lb_pred = self.net_uv(self.X_lb[:, 0:1], self.X_lb[:, 1:2])\n",
    "        self.u_ub_pred, self.v_ub_pred, self.u_x_ub_pred, self.v_x_ub_pred = self.net_uv(self.X_ub[:, 0:1], self.X_ub[:, 1:2])\n",
    "        \n",
    "        self.f_u_pred, self.f_v_pred = self.net_f_uv(self.X_f[:, 0:1], self.X_f[:, 1:2])\n",
    "        \n",
    "        # initial condition + boundary condition + PDE constraint\n",
    "        MSE = loss(self.u0_pred, self.u0) + loss(self.v0_pred, self.v0) + \\\n",
    "            loss(self.u_lb_pred, self.u_ub_pred) + loss(self.v_lb_pred, self.v_ub_pred) + \\\n",
    "            loss(self.u_x_lb_pred, self.u_x_ub_pred) + loss(self.v_x_lb_pred, self.v_x_ub_pred) + \\\n",
    "            loss(self.f_u_pred, torch.zeros_like(self.f_u_pred)) + loss(self.f_v_pred, torch.zeros_like(self.f_v_pred))\n",
    "\n",
    "        return MSE\n",
    "    \n",
    "    def train(self, epochs = 1e+4, lr = 1e-3):\n",
    "        # Optimizer\n",
    "        optimizer = adam.Adam(self.model.parameters(), lr=lr)\n",
    "        \n",
    "        # Training\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            optimizer.zero_grad()\n",
    "            loss = self.loss_function()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if epoch % 100 == 0:\n",
    "                print('Epoch: %d, Loss: %.3e' % (epoch, loss.item()))\n",
    "\n",
    "    def predict(self, X_star):\n",
    "        u_star, v_star, f_u_star, f_v_star = self.forward(X_star[:, 0:1], X_star[:, 1:2])\n",
    "        return u_star.detach().numpy(), v_star.detach().numpy(), f_u_star.detach().numpy(), f_v_star.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SymbolAlreadyExposedError",
     "evalue": "Symbol Zeros is already exposed as ().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSymbolAlreadyExposedError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/finleyyu/Library/CloudStorage/Dropbox/Germany/2023ws/Generative neural networks/GenerativePINNs/basic pinn.ipynb 单元格 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/finleyyu/Library/CloudStorage/Dropbox/Germany/2023ws/Generative%20neural%20networks/GenerativePINNs/basic%20pinn.ipynb#X11sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m model \u001b[39m=\u001b[39m PhysicsInformedNN(x0, u0, v0, tb, X_f, layers, lb, ub)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/finleyyu/Library/CloudStorage/Dropbox/Germany/2023ws/Generative%20neural%20networks/GenerativePINNs/basic%20pinn.ipynb#X11sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()                \n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/finleyyu/Library/CloudStorage/Dropbox/Germany/2023ws/Generative%20neural%20networks/GenerativePINNs/basic%20pinn.ipynb#X11sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m model\u001b[39m.\u001b[39mtrain(\u001b[39m50000\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/finleyyu/Library/CloudStorage/Dropbox/Germany/2023ws/Generative%20neural%20networks/GenerativePINNs/basic%20pinn.ipynb#X11sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTraining time: \u001b[39m\u001b[39m%.4f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/finleyyu/Library/CloudStorage/Dropbox/Germany/2023ws/Generative%20neural%20networks/GenerativePINNs/basic%20pinn.ipynb#X11sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# Predictions\u001b[39;00m\n",
      "\u001b[1;32m/Users/finleyyu/Library/CloudStorage/Dropbox/Germany/2023ws/Generative neural networks/GenerativePINNs/basic pinn.ipynb 单元格 5\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/finleyyu/Library/CloudStorage/Dropbox/Germany/2023ws/Generative%20neural%20networks/GenerativePINNs/basic%20pinn.ipynb#X11sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m, epochs \u001b[39m=\u001b[39m \u001b[39m1e+4\u001b[39m, lr \u001b[39m=\u001b[39m \u001b[39m1e-3\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/finleyyu/Library/CloudStorage/Dropbox/Germany/2023ws/Generative%20neural%20networks/GenerativePINNs/basic%20pinn.ipynb#X11sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     \u001b[39m# Optimizer\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/finleyyu/Library/CloudStorage/Dropbox/Germany/2023ws/Generative%20neural%20networks/GenerativePINNs/basic%20pinn.ipynb#X11sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     optimizer \u001b[39m=\u001b[39m adam\u001b[39m.\u001b[39mAdam(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlr)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/finleyyu/Library/CloudStorage/Dropbox/Germany/2023ws/Generative%20neural%20networks/GenerativePINNs/basic%20pinn.ipynb#X11sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     \u001b[39m# Training\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/finleyyu/Library/CloudStorage/Dropbox/Germany/2023ws/Generative%20neural%20networks/GenerativePINNs/basic%20pinn.ipynb#X11sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(epochs)):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/adam.py:45\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid weight_decay value: \u001b[39m\u001b[39m{\u001b[39;00mweight_decay\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m defaults \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(lr\u001b[39m=\u001b[39mlr, betas\u001b[39m=\u001b[39mbetas, eps\u001b[39m=\u001b[39meps,\n\u001b[1;32m     42\u001b[0m                 weight_decay\u001b[39m=\u001b[39mweight_decay, amsgrad\u001b[39m=\u001b[39mamsgrad,\n\u001b[1;32m     43\u001b[0m                 maximize\u001b[39m=\u001b[39mmaximize, foreach\u001b[39m=\u001b[39mforeach, capturable\u001b[39m=\u001b[39mcapturable,\n\u001b[1;32m     44\u001b[0m                 differentiable\u001b[39m=\u001b[39mdifferentiable, fused\u001b[39m=\u001b[39mfused)\n\u001b[0;32m---> 45\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(params, defaults)\n\u001b[1;32m     47\u001b[0m \u001b[39mif\u001b[39;00m fused:\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m differentiable:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:266\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    263\u001b[0m     param_groups \u001b[39m=\u001b[39m [{\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m: param_groups}]\n\u001b[1;32m    265\u001b[0m \u001b[39mfor\u001b[39;00m param_group \u001b[39min\u001b[39;00m param_groups:\n\u001b[0;32m--> 266\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_param_group(cast(\u001b[39mdict\u001b[39m, param_group))\n\u001b[1;32m    268\u001b[0m \u001b[39m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[39m# which I don't think exists\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[39m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warned_capturable_if_run_uncaptured \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_compile.py:22\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(fn)\n\u001b[1;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 22\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_dynamo\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mdisable(fn, recursive)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_dynamo/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m allowed_functions, convert_frame, eval_frame, resume_execution\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbackends\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mregistry\u001b[39;00m \u001b[39mimport\u001b[39;00m list_backends, register_backend\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconvert_frame\u001b[39;00m \u001b[39mimport\u001b[39;00m replay\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_dynamo/allowed_functions.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_functorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdeprecated\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mdeprecated_func\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfx\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_symbolic_trace\u001b[39;00m \u001b[39mimport\u001b[39;00m is_fx_tracing\n\u001b[0;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m config\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexternal_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m is_compiling\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m is_safe_constant, NP_SUPPORTED_MODULES\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_dynamo/config.py:49\u001b[0m\n\u001b[1;32m     41\u001b[0m specialize_int \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39m# Assume these functions return constants\u001b[39;00m\n\u001b[1;32m     44\u001b[0m constant_functions \u001b[39m=\u001b[39m {\n\u001b[1;32m     45\u001b[0m     torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_scripting: \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m     torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_tracing: \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m     torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_get_tracing_state: \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m     torch\u001b[39m.\u001b[39mfx\u001b[39m.\u001b[39m_symbolic_trace\u001b[39m.\u001b[39mis_fx_tracing: \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m---> 49\u001b[0m     torch\u001b[39m.\u001b[39monnx\u001b[39m.\u001b[39mis_in_onnx_export: \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     50\u001b[0m     external_utils\u001b[39m.\u001b[39mis_compiling: \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     51\u001b[0m     torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39mis_compiling: \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     52\u001b[0m }\n\u001b[1;32m     54\u001b[0m \u001b[39m# legacy config, does nothing now!\u001b[39;00m\n\u001b[1;32m     55\u001b[0m dynamic_shapes \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/__init__.py:1831\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m   1829\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m _lazy_modules:\n\u001b[1;32m   1830\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mimportlib\u001b[39;00m\n\u001b[0;32m-> 1831\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m__name__\u001b[39m)\n\u001b[1;32m   1833\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodule \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/onnx/__init__.py:46\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39merrors\u001b[39;00m \u001b[39mimport\u001b[39;00m CheckerError  \u001b[39m# Backwards compatibility\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     35\u001b[0m     _optimize_graph,\n\u001b[1;32m     36\u001b[0m     _run_symbolic_function,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     unregister_custom_op_symbolic,\n\u001b[1;32m     44\u001b[0m )\n\u001b[0;32m---> 46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_internal\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexporter\u001b[39;00m \u001b[39mimport\u001b[39;00m (  \u001b[39m# usort:skip. needs to be last to avoid circular import\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     ExportOptions,\n\u001b[1;32m     48\u001b[0m     ExportOutput,\n\u001b[1;32m     49\u001b[0m     ExportOutputSerializer,\n\u001b[1;32m     50\u001b[0m     dynamo_export,\n\u001b[1;32m     51\u001b[0m     OnnxExporterError,\n\u001b[1;32m     52\u001b[0m     enable_fake_mode,\n\u001b[1;32m     53\u001b[0m     OnnxRegistry,\n\u001b[1;32m     54\u001b[0m     DiagnosticOptions,\n\u001b[1;32m     55\u001b[0m )\n\u001b[1;32m     57\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_internal\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnxruntime\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     58\u001b[0m     is_onnxrt_backend_supported,\n\u001b[1;32m     59\u001b[0m     OrtBackend \u001b[39mas\u001b[39;00m _OrtBackend,\n\u001b[1;32m     60\u001b[0m     OrtBackendOptions \u001b[39mas\u001b[39;00m _OrtBackendOptions,\n\u001b[1;32m     61\u001b[0m     OrtExecutionProvider \u001b[39mas\u001b[39;00m _OrtExecutionProvider,\n\u001b[1;32m     62\u001b[0m )\n\u001b[1;32m     64\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m     65\u001b[0m     \u001b[39m# Modules\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msymbolic_helper\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mis_onnxrt_backend_supported\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    111\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/onnx/_internal/exporter.py:42\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnx\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_internal\u001b[39;00m \u001b[39mimport\u001b[39;00m _beartype, io_adapter\n\u001b[1;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnx\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_internal\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdiagnostics\u001b[39;00m \u001b[39mimport\u001b[39;00m infra\n\u001b[0;32m---> 42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnx\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_internal\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfx\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     43\u001b[0m     decomposition_table,\n\u001b[1;32m     44\u001b[0m     patcher \u001b[39mas\u001b[39;00m patcher,\n\u001b[1;32m     45\u001b[0m     registration,\n\u001b[1;32m     46\u001b[0m     serialization \u001b[39mas\u001b[39;00m fx_serialization,\n\u001b[1;32m     47\u001b[0m )\n\u001b[1;32m     49\u001b[0m \u001b[39m# We can only import onnx from this module in a type-checking context to ensure that\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39m# 'import torch.onnx' continues to work without having 'onnx' installed. We fully\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39m# 'import onnx' inside of dynamo_export (by way of _assert_dependencies).\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[39mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/onnx/_internal/fx/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpatcher\u001b[39;00m \u001b[39mimport\u001b[39;00m ONNXTorchPatcher\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mserialization\u001b[39;00m \u001b[39mimport\u001b[39;00m save_model_with_external_data\n\u001b[1;32m      5\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msave_model_with_external_data\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mONNXTorchPatcher\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/onnx/_internal/fx/patcher.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m     \u001b[39m# safetensors is not an exporter requirement, but needed for some huggingface models\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39msafetensors\u001b[39;00m  \u001b[39m# type: ignore[import]  # noqa: F401\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtransformers\u001b[39;00m  \u001b[39m# type: ignore[import]\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39msafetensors\u001b[39;00m \u001b[39mimport\u001b[39;00m torch \u001b[39mas\u001b[39;00m safetensors_torch  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     has_safetensors_and_transformers \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/__init__.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m__name__\u001b[39m)  \u001b[39m# pylint: disable=invalid-name\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m# Files and general utilities\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfile_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m (TRANSFORMERS_CACHE, PYTORCH_TRANSFORMERS_CACHE, PYTORCH_PRETRAINED_BERT_CACHE,\n\u001b[1;32m     21\u001b[0m                          cached_path, add_start_docstrings, add_end_docstrings,\n\u001b[1;32m     22\u001b[0m                          WEIGHTS_NAME, TF2_WEIGHTS_NAME, TF_WEIGHTS_NAME, CONFIG_NAME,\n\u001b[1;32m     23\u001b[0m                          is_tf_available, is_torch_available)\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m (is_sklearn_available,\n\u001b[1;32m     26\u001b[0m                    InputExample, InputFeatures, DataProcessor,\n\u001b[1;32m     27\u001b[0m                    glue_output_modes, glue_convert_examples_to_features,\n\u001b[1;32m     28\u001b[0m                    glue_processors, glue_tasks_num_labels)\n\u001b[1;32m     30\u001b[0m \u001b[39mif\u001b[39;00m is_sklearn_available():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/file_utils.py:29\u001b[0m\n\u001b[1;32m     26\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m__name__\u001b[39m)  \u001b[39m# pylint: disable=invalid-name\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 29\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mhasattr\u001b[39m(tf, \u001b[39m'\u001b[39m\u001b[39m__version__\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mint\u001b[39m(tf\u001b[39m.\u001b[39m__version__[\u001b[39m0\u001b[39m]) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m     31\u001b[0m     _tf_available \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m  \u001b[39m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/__init__.py:476\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(_current_module, \u001b[39m\"\u001b[39m\u001b[39mkeras\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    475\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 476\u001b[0m     _keras\u001b[39m.\u001b[39m_load()\n\u001b[1;32m    477\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/lazy_loader.py:41\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_module_globals[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_name] \u001b[39m=\u001b[39m module\n\u001b[1;32m     44\u001b[0m \u001b[39m# Emit a warning if one was specified\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/__init__.py:21\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/models/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m Functional\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/engine/functional.py:26\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtensor\u001b[39;00m \u001b[39mimport\u001b[39;00m layout_map \u001b[39mas\u001b[39;00m layout_map_lib\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/backend/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m \u001b[39mimport\u001b[39;00m experimental\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39mabs\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39mall\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/backend/experimental/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m \u001b[39mimport\u001b[39;00m disable_tf_random_generator\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m \u001b[39mimport\u001b[39;00m enable_tf_random_generator\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m \u001b[39mimport\u001b[39;00m is_tf_random_generator_enabled\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/__init__.py:21\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m applications\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/applications/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Keras Applications are premade architectures with pre-trained weights.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconvnext\u001b[39;00m \u001b[39mimport\u001b[39;00m ConvNeXtBase\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconvnext\u001b[39;00m \u001b[39mimport\u001b[39;00m ConvNeXtLarge\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconvnext\u001b[39;00m \u001b[39mimport\u001b[39;00m ConvNeXtSmall\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/applications/convnext.py:28\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m initializers\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m layers\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/backend.py:35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistribute\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute_coordinator_utils \u001b[39mas\u001b[39;00m dc\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtensor\u001b[39;00m \u001b[39mimport\u001b[39;00m dtensor_api \u001b[39mas\u001b[39;00m dtensor\n\u001b[0;32m---> 35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_tensor\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m control_flow_util\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m object_identity\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/keras_tensor.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Keras Input Tensor used to track functional API Topology.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m object_identity\n\u001b[1;32m     21\u001b[0m \u001b[39m# isort: off\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m structure\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/__init__.py:20\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Public Keras utilities.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m# isort: off\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[39m# Serialization related\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mserialization_lib\u001b[39;00m \u001b[39mimport\u001b[39;00m deserialize_keras_object\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mserialization_lib\u001b[39;00m \u001b[39mimport\u001b[39;00m serialize_keras_object\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mobject_registration\u001b[39;00m \u001b[39mimport\u001b[39;00m CustomObjectScope\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m \u001b[39mimport\u001b[39;00m object_registration\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m serialization \u001b[39mas\u001b[39;00m legacy_serialization\n\u001b[0;32m---> 28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaved_model\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m in_tf_saved_model_scope\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m generic_utils\n\u001b[1;32m     31\u001b[0m \u001b[39m# isort: off\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/legacy/saved_model/utils.py:30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m tf_contextlib\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader\n\u001b[0;32m---> 30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayer_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m CallFunctionSpec\n\u001b[1;32m     32\u001b[0m training_lib \u001b[39m=\u001b[39m LazyLoader(\u001b[39m\"\u001b[39m\u001b[39mtraining_lib\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mglobals\u001b[39m(), \u001b[39m\"\u001b[39m\u001b[39mkeras.src.engine.training\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39muse_wrapped_call\u001b[39m(\n\u001b[1;32m     36\u001b[0m     layer, call_fn, call_spec, default_training_value\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, return_method\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     37\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/layer_utils.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m initializers\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m io_utils\n\u001b[1;32m     29\u001b[0m \u001b[39m# isort: off\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/initializers/__init__.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minitializers\u001b[39;00m \u001b[39mimport\u001b[39;00m initializers\n\u001b[0;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minitializers\u001b[39;00m \u001b[39mimport\u001b[39;00m initializers_v1\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m \u001b[39mimport\u001b[39;00m serialization_lib\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m serialization \u001b[39mas\u001b[39;00m legacy_serialization\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/initializers/initializers_v1.py:32\u001b[0m\n\u001b[1;32m     29\u001b[0m _v1_glorot_uniform_initializer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mglorot_uniform_initializer\n\u001b[1;32m     30\u001b[0m _v1_glorot_normal_initializer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mglorot_normal_initializer\n\u001b[0;32m---> 32\u001b[0m keras_export(v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mkeras.initializers.Zeros\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkeras.initializers.zeros\u001b[39m\u001b[39m\"\u001b[39m])(\n\u001b[1;32m     33\u001b[0m     _v1_zeros_initializer\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     35\u001b[0m keras_export(v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mkeras.initializers.Ones\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkeras.initializers.ones\u001b[39m\u001b[39m\"\u001b[39m])(\n\u001b[1;32m     36\u001b[0m     _v1_ones_initializer\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     38\u001b[0m keras_export(v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mkeras.initializers.Constant\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkeras.initializers.constant\u001b[39m\u001b[39m\"\u001b[39m])(\n\u001b[1;32m     39\u001b[0m     _v1_constant_initializer\n\u001b[1;32m     40\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/tf_export.py:348\u001b[0m, in \u001b[0;36mapi_export.__call__\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    345\u001b[0m   \u001b[39mdelattr\u001b[39m(undecorated_f, api_names_attr_v1)\n\u001b[1;32m    347\u001b[0m _, undecorated_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(func)\n\u001b[0;32m--> 348\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_attr(undecorated_func, api_names_attr, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_names)\n\u001b[1;32m    349\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_attr(undecorated_func, api_names_attr_v1, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_names_v1)\n\u001b[1;32m    351\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_names:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/tf_export.py:364\u001b[0m, in \u001b[0;36mapi_export.set_attr\u001b[0;34m(self, func, api_names_attr, names)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mif\u001b[39;00m api_names_attr \u001b[39min\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[1;32m    363\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_allow_multiple_exports:\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mraise\u001b[39;00m SymbolAlreadyExposedError(\n\u001b[1;32m    365\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mSymbol \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is already exposed as \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m    366\u001b[0m         (func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39mgetattr\u001b[39m(func, api_names_attr)))  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[39msetattr\u001b[39m(func, api_names_attr, names)\n",
      "\u001b[0;31mSymbolAlreadyExposedError\u001b[0m: Symbol Zeros is already exposed as ()."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "from pyDOE import lhs\n",
    "import time\n",
    "\n",
    "# Hyperparameters\n",
    "noise = 0.0        \n",
    "lb = np.array([-5.0, 0.0]) # lower bound for [x, t]\n",
    "ub = np.array([5.0, np.pi/2]) # upper bound for [x, t]\n",
    "N0 = 50 # number of data for initial samples\n",
    "N_b = 50 # number of data for boundary samples\n",
    "N_f = 20000 # number of data for collocation points\n",
    "\n",
    "# Define the physics-informed neural network\n",
    "layers = [2, 100, 100, 100, 100, 2]\n",
    "\n",
    "# Load data from simulated dataset\n",
    "data = scipy.io.loadmat('./Data/NLS.mat')\n",
    "\n",
    "\n",
    "t = data['tt'].flatten()[:,None]\n",
    "x = data['x'].flatten()[:,None]\n",
    "Exact = data['uu']\n",
    "Exact_h = np.sqrt(np.real(Exact)**2 + np.imag(Exact)**2)\n",
    "X, T = np.meshgrid(x,t)\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "h_star = Exact_h.T.flatten()[:,None]\n",
    "v_star = np.imag(Exact).T.flatten()[:,None]\n",
    "u_star = np.real(Exact).T.flatten()[:,None]\n",
    "\n",
    "# Initial and boundary data\n",
    "idx_x = np.random.choice(x.shape[0], N0, replace=False)\n",
    "x0 = x[idx_x,:]\n",
    "u0 = np.real(Exact[idx_x,0:1]) # or computed using h(0, x) = 2*sech(x)\n",
    "v0 = np.imag(Exact[idx_x,0:1])\n",
    "tb = t[np.random.choice(t.shape[0], N_b, replace=False),:] # random time samples\n",
    "\n",
    "# Collocation points\n",
    "X_f = lb + (ub-lb)*lhs(2, N_f)\n",
    "\n",
    "# Train the model\n",
    "model = PhysicsInformedNN(x0, u0, v0, tb, X_f, lb, ub, layers)\n",
    "start_time = time.time()                \n",
    "model.train(50000)\n",
    "print('Training time: %.4f' % (time.time() - start_time))\n",
    "\n",
    "# Predictions\n",
    "u_pred, v_pred, _, _ = model.predict(X_star)\n",
    "h_pred = np.sqrt(u_pred**2 + v_pred**2)\n",
    "        \n",
    "# Errors\n",
    "errors = {'u': np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2),\n",
    "          'v': np.linalg.norm(v_star-v_pred,2)/np.linalg.norm(v_star,2),\n",
    "          'h': np.linalg.norm(h_star-h_pred,2)/np.linalg.norm(h_star,2)}\n",
    "print('Errors: ', errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface_hub.constants does not have attribute HF_HUB_CACHE\n"
     ]
    }
   ],
   "source": [
    "import huggingface_hub.constants\n",
    "\n",
    "if hasattr(huggingface_hub.constants, 'HF_HUB_CACHE'):\n",
    "    print(\"huggingface_hub.constants has attribute HF_HUB_CACHE\")\n",
    "else:\n",
    "    print(\"huggingface_hub.constants does not have attribute HF_HUB_CACHE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
